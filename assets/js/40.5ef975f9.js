(window.webpackJsonp=window.webpackJsonp||[]).push([[40],{761:function(a,t,s){"use strict";s.r(t);var e=s(97),r=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"hdfs-shell"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-shell"}},[a._v("#")]),a._v(" HDFS Shell")]),a._v(" "),s("p",[a._v("通过命令行来进一步跟 HDFS 文件系统进行交互，可以执行所有常用的文件系统的操作，例如：读取文件、创建目录、移动文件、删除文件等等。同时可以通过 "),s("code",[a._v("hdfs dfs -help")]),a._v(" 命令来获取每个命令的详细帮助文档。")]),a._v(" "),s("h2",{attrs:{id:"常用的-hdfs-shell-命令"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#常用的-hdfs-shell-命令"}},[a._v("#")]),a._v(" 常用的 HDFS Shell 命令")]),a._v(" "),s("table",[s("thead",[s("tr",[s("th",[a._v("命令")]),a._v(" "),s("th",[a._v("功能")])])]),a._v(" "),s("tbody",[s("tr",[s("td",[a._v("-help")]),a._v(" "),s("td",[a._v("显示命令的帮助信息")])]),a._v(" "),s("tr",[s("td",[a._v("-ls (-R) [path]")]),a._v(" "),s("td",[a._v("显示当前目录下的所有文件")])]),a._v(" "),s("tr",[s("td",[a._v("-du (-S) [path]")]),a._v(" "),s("td",[a._v("显示目录中所有的文件大小")])]),a._v(" "),s("tr",[s("td",[a._v("-count (-q) [path]")]),a._v(" "),s("td",[a._v("显示文件中的文件数量")])]),a._v(" "),s("tr",[s("td",[a._v("-mv [src] [dst]")]),a._v(" "),s("td",[a._v("移动多个文件到目标目录")])]),a._v(" "),s("tr",[s("td",[a._v("-cp [src] [dst]")]),a._v(" "),s("td",[a._v("复制多个文件到目标目录")])]),a._v(" "),s("tr",[s("td",[a._v("-rm (-R) [path]")]),a._v(" "),s("td",[a._v("删除文件（夹）")])]),a._v(" "),s("tr",[s("td",[a._v("-put [localsrc] [dst]")]),a._v(" "),s("td",[a._v("本地文件上传到 hdfs 中")])]),a._v(" "),s("tr",[s("td",[a._v("-copyFromLocal [localsrc] [dst]")]),a._v(" "),s("td",[a._v("以 put 相同")])]),a._v(" "),s("tr",[s("td",[a._v("-moveFromLocal [localsrc] [dst]")]),a._v(" "),s("td",[a._v("本地文件剪切到 hdfs 中")])]),a._v(" "),s("tr",[s("td",[a._v("-get [src] [localdst]")]),a._v(" "),s("td",[a._v("从 hdfs 中下载文件到本地")])]),a._v(" "),s("tr",[s("td",[a._v("-getmerge [src] [localdst]")]),a._v(" "),s("td",[a._v("将源目录中的所有文件排序合并到一个文件中")])]),a._v(" "),s("tr",[s("td",[a._v("-cat [src]")]),a._v(" "),s("td",[a._v("在 hdfs 中显示文件内容")])]),a._v(" "),s("tr",[s("td",[a._v("-text [src]")]),a._v(" "),s("td",[a._v("在 hdfs 中显示文件内容")])]),a._v(" "),s("tr",[s("td",[a._v("-copyToLocal [src] [localdst]")]),a._v(" "),s("td",[a._v("复制到本地")])]),a._v(" "),s("tr",[s("td",[a._v("-moveToLocal [src] [localdst]")]),a._v(" "),s("td",[a._v("移动到本地")])]),a._v(" "),s("tr",[s("td",[a._v("-mkdir (-p) [paths]")]),a._v(" "),s("td",[a._v("创建目录")])]),a._v(" "),s("tr",[s("td",[a._v("-touchz [path]")]),a._v(" "),s("td",[a._v("创建一个空文件")])])])]),a._v(" "),s("h2",{attrs:{id:"以下是部分命令的具体使用方法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#以下是部分命令的具体使用方法"}},[a._v("#")]),a._v(" 以下是部分命令的具体使用方法")]),a._v(" "),s("h3",{attrs:{id:"_1-mkdir-创建目录"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-mkdir-创建目录"}},[a._v("#")]),a._v(" 1. mkdir 创建目录")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -mkdir (-p) [paths]")])]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 创建 user 目录")]),a._v("\nhdfs dfs -mkdir /user\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 同时创建多个目录")]),a._v("\nhdfs dfs -mkdir /user/d1 /user/d2\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 当创建多级目录时，使用 -p 自动创建上级目录")]),a._v("\nhdfs dfs -mkdir -p /user/hadoop/dir1 /user/hadoop/dir2\n")])])]),s("h3",{attrs:{id:"_2-put-上传文件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-put-上传文件"}},[a._v("#")]),a._v(" 2. put 上传文件")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -put <localsrc> ... <dst>")])]),a._v(" "),s("p",[a._v("从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 单个文件上传")]),a._v("\nhdfs dfs -put b.txt /user/hadoop/dir1\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 多个文件上传")]),a._v("\nhdfs dfs -put a.xml b.xml /user/hadoop/dir1\n")])])]),s("h3",{attrs:{id:"_3-ls-列出文件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-ls-列出文件"}},[a._v("#")]),a._v(" 3. ls 列出文件")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -ls (-R)")])]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 列出 hdfs 文件系统的根目录文件")]),a._v("\nhdfs dfs -ls /\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 列出 hdfs 文件系统所有的目录和文件")]),a._v("\nhdfs dfs -ls -R /\n")])])]),s("h3",{attrs:{id:"_4-text、cat"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-text、cat"}},[a._v("#")]),a._v(" 4. text、cat")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -text[-cat]")])]),a._v(" "),s("p",[a._v("将文本文件或某些格式的非文本文件通过文本格式输出")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("hdfs dfs -text /user/hadoop/dir1/a.xml\nhdfs dfs -cat /user/hadoop/dir1/a.xml\n")])])]),s("h3",{attrs:{id:"_5-get"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-get"}},[a._v("#")]),a._v(" 5. get")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -get [src] [localdist]")])]),a._v(" "),s("p",[a._v("将 HDFS 中的文件被复制到本地")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("hdfs dfs -get /user/hadoop/dir1/a.xml ~/tmp/user/\n")])])]),s("h3",{attrs:{id:"_6-rm-r"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6-rm-r"}},[a._v("#")]),a._v(" 6. rm (-R)")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -rm (-R) [path]")])]),a._v(" "),s("p",[a._v("每次可以删除多个文件或目录")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 删除指定的文件。只删除空目录或文件")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -rm /user/hadoop/dir1/a.xml")]),a._v("\nDeleted /user/hadoop/dir1/a.xml\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 删除文件或目录")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -rm -R /user/hadoop/dir1")]),a._v("\nDeleted /user/hadoop/dir1\n")])])]),s("h3",{attrs:{id:"_7-chmod"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7-chmod"}},[a._v("#")]),a._v(" 7. chmod")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -chmod (-R) [num,num,num] [path]")])]),a._v(" "),s("p",[a._v("改变文件的权限。使用 -R 将改变在目录结构下递归进行。命令使用者必须是root用户下")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -chmod 777 /user/hadoop/dir2")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -ls /user/hadoop/")]),a._v("\ndrwxrwxrwx   - root supergroup          "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2020")]),a._v("-05-05 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("21")]),a._v(":00 /user/hadoop/dir2\n")])])]),s("h3",{attrs:{id:"_8-copyfromlocal"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_8-copyfromlocal"}},[a._v("#")]),a._v(" 8. copyFromLocal")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -copyFromLocal <localsrc> ... <dst>")])]),a._v(" "),s("p",[a._v("与 put 相类似，也可以从从键盘 读取输入到 hdfs file 中。")]),a._v(" "),s("h3",{attrs:{id:"_9-copytolocal"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_9-copytolocal"}},[a._v("#")]),a._v(" 9. copyToLocal")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -copyToLocal [src] [localdist]")])]),a._v(" "),s("p",[a._v("与 get 相类似，将 HDFS 中的文件被复制到本地。")]),a._v(" "),s("h3",{attrs:{id:"_10-cp"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_10-cp"}},[a._v("#")]),a._v(" 10. cp")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -cp <src> ... <dst>")])]),a._v(" "),s("p",[a._v("将文件从 hdfs 中复制到目标路径，允许有多个源路径，此时目标路径必须是目录")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -mkdir -p /user/hadoop/file1 /user/hadoop/file2")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -put output/part-r-00000 /user/hadoop/file1")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 将part-r-00000复制到file2文件中")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -cp /user/hadoop/file1/part-r-00000 /user/hadoop/file2")]),a._v("\n")])])]),s("h3",{attrs:{id:"_11-du"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_11-du"}},[a._v("#")]),a._v(" 11. du")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -du <path>")])]),a._v(" "),s("p",[a._v("显示目录中的所有文件的大小")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -du /user/hadoop/file1/")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("55")]),a._v("  /user/hadoop/file1/part-r-00000\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -du /user/hadoop/")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("    /user/hadoop/dir2\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("580")]),a._v("  /user/hadoop/dis1\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("55")]),a._v("   /user/hadoop/file1\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("55")]),a._v("   /user/hadoop/file2\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#")]),a._v("\n")])])]),s("h3",{attrs:{id:"_12-expunge"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-expunge"}},[a._v("#")]),a._v(" 12. expunge")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -expunge")])]),a._v(" "),s("p",[a._v("用来清空回收站，hdfs 回收站默认不开启")]),a._v(" "),s("h3",{attrs:{id:"_13-getmerge"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_13-getmerge"}},[a._v("#")]),a._v(" 13. getmerge")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -getmerge <src> <local>")])]),a._v(" "),s("p",[a._v("将 hdfs 指定目录下所有文件排序后合并到 local 指定的文件中，文件不存在时会自动创建，文件存在时会覆盖里面的内容。")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# cp input/wc.txt input/wc2.txt")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -put input/* /user/hadoop/file2")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfs -getmerge /user/hadoop/file2 input/newWC.txt")]),a._v("\n")])])]),s("h3",{attrs:{id:"_14-mv"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_14-mv"}},[a._v("#")]),a._v(" 14. mv")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -mv <src> ... <dist>")])]),a._v(" "),s("p",[a._v("移动 HDFS 上的文件")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("hdfs dfs -mv /user/hadoop/file1 /user/hadoop/file2\n")])])]),s("h3",{attrs:{id:"_15-tail"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_15-tail"}},[a._v("#")]),a._v(" 15. tail")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -tail [-f] <path>")])]),a._v(" "),s("p",[a._v("将文件尾部 1KB 字节的内容输出到控制台中")]),a._v(" "),s("h3",{attrs:{id:"_16-touchz"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_16-touchz"}},[a._v("#")]),a._v(" 16. touchz")]),a._v(" "),s("p",[a._v("使用方法："),s("code",[a._v("hdfs dfs -touchz <pathname>")])]),a._v(" "),s("p",[a._v("创建一个空文件")]),a._v(" "),s("h2",{attrs:{id:"hadoop-系统管理命令"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-系统管理命令"}},[a._v("#")]),a._v(" Hadoop 系统管理命令")]),a._v(" "),s("p",[a._v("Hadoop 除了操作文件系统外，还提供了系统的管理命令，包括开启服务、关闭服务、格式化、安全模式设置等命令：")]),a._v(" "),s("h3",{attrs:{id:"查看-hadoop-版本"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#查看-hadoop-版本"}},[a._v("#")]),a._v(" 查看 Hadoop 版本")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop version")]),a._v("\n")])])]),s("h3",{attrs:{id:"启动和停止-hadoop-所有进程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#启动和停止-hadoop-所有进程"}},[a._v("#")]),a._v(" 启动和停止 Hadoop 所有进程")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# start-all.sh ")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# stop-all.sh ")]),a._v("\n")])])]),s("h3",{attrs:{id:"格式化一个新的分布式文件系统"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#格式化一个新的分布式文件系统"}},[a._v("#")]),a._v(" 格式化一个新的分布式文件系统")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop namenode -format ")]),a._v("\n")])])]),s("h3",{attrs:{id:"启动和停止-namenode"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#启动和停止-namenode"}},[a._v("#")]),a._v(" 启动和停止 NameNode")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# start-dfs.sh ")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# stop-dfs.sh ")]),a._v("\n")])])]),s("h3",{attrs:{id:"启动和停止-yarn"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#启动和停止-yarn"}},[a._v("#")]),a._v(" 启动和停止 Yarn")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# start-yarn.sh ")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# stop-yarn.sh ")]),a._v("\n")])])]),s("h3",{attrs:{id:"平衡-hdfs-文件块分布"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#平衡-hdfs-文件块分布"}},[a._v("#")]),a._v(" 平衡 hdfs 文件块分布")]),a._v(" "),s("p",[a._v("如果管理员发现某些 DataNode 保存数据过多，某些 DataNode 保存数据相对较少，可以使用上述命令手动启动内部的均衡过程。")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop balancer")]),a._v("\n")])])]),s("h2",{attrs:{id:"hadoop-安全模式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-安全模式"}},[a._v("#")]),a._v(" Hadoop 安全模式")]),a._v(" "),s("p",[a._v("NameNode 在启动时会自动进入安全模式，安全模式时 NameNode 的一种状态，在这个阶段，文件系统不允许有任何修改。安全模式的目的在系统启动时检查各个 DataNode 上的数据块有效性，同时根据策略对数据块进行必要的复制或删除，当数据块副本满足最小副本数条件时，会自动退出安全模式。")]),a._v(" "),s("p",[s("code",[a._v("注：当 HDFS 进入安全模式后，会导致 Hive 和 HBase 的启动异常 。")])]),a._v(" "),s("h3",{attrs:{id:"使用方式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#使用方式"}},[a._v("#")]),a._v(" 使用方式")]),a._v(" "),s("p",[s("code",[a._v("Usage: hdfs dfsadmin [-safemode enter | leave | get | wait | forceExit]")])]),a._v(" "),s("h3",{attrs:{id:"查看-hadoop-是否处于安全模式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#查看-hadoop-是否处于安全模式"}},[a._v("#")]),a._v(" 查看 Hadoop 是否处于安全模式")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfsadmin -safemode get")]),a._v("\nSafe mode is OFF\n")])])]),s("h3",{attrs:{id:"手动进入安全模式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#手动进入安全模式"}},[a._v("#")]),a._v(" 手动进入安全模式")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfsadmin -safemode enter")]),a._v("\nSafe mode is ON\n")])])]),s("p",[a._v("此时进入安全模式状态。")]),a._v(" "),s("h3",{attrs:{id:"退出安全模式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#退出安全模式"}},[a._v("#")]),a._v(" 退出安全模式")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfsadmin -safemode leave")]),a._v("\nSafe mode is OFF\n")])])]),s("p",[a._v("此时已退出安全模式状态。")]),a._v(" "),s("h3",{attrs:{id:"列出所有当前支持的命令"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#列出所有当前支持的命令"}},[a._v("#")]),a._v(" 列出所有当前支持的命令")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@bigdata11 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfsadmin -help")]),a._v("\n")])])]),s("h2",{attrs:{id:"参考资料"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[a._v("#")]),a._v(" 参考资料")]),a._v(" "),s("p",[s("a",{attrs:{href:"https://hadoop.apache.org/docs/r2.10.0/hadoop-project-dist/hadoop-common/FileSystemShell.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("Apache Hadoop 2.10.0 > HDFS Shell"),s("OutboundLink")],1)])])}),[],!1,null,null,null);t.default=r.exports}}]);