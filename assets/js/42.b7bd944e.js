(window.webpackJsonp=window.webpackJsonp||[]).push([[42],{774:function(a,t,s){"use strict";s.r(t);var e=s(97),n=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"hdfs-的架构设计及组件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-的架构设计及组件"}},[a._v("#")]),a._v(" HDFS 的架构设计及组件")]),a._v(" "),s("h2",{attrs:{id:"hdfs-的特点"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-的特点"}},[a._v("#")]),a._v(" HDFS 的特点")]),a._v(" "),s("ol",[s("li",[s("strong",[a._v("高容错：")]),a._v(" 由于 HDFS 采用数据的多副本方案，所以部分硬件的损坏不会导致全部数据的丢失。")]),a._v(" "),s("li",[s("strong",[a._v("高吞吐量：")]),a._v(" HDFS 设计的重点是支持高吞吐量的数据访问，而不是低延迟的数据访问。")]),a._v(" "),s("li",[s("strong",[a._v("大文件支持：")]),a._v(" HDFS 适合于大文件的存储，文档的大小应该是是 GB 到 TB 级别的。")]),a._v(" "),s("li",[s("strong",[a._v("简单一致性模型：")]),a._v(" HDFS 更适合于一次写入多次读取 (write-once-read-many) 的访问模型。支持将内容追加到文件末尾，但不支持数据的随机访问，不能从文件任意位置新增数据。")]),a._v(" "),s("li",[s("strong",[a._v("跨平台移植性：")]),a._v(" HDFS 具有良好的跨平台移植性，这使得其他大数据计算框架都将其作为数据持久化存储的首选方案。")])]),a._v(" "),s("h2",{attrs:{id:"hdfs-的架构设计"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-的架构设计"}},[a._v("#")]),a._v(" HDFS 的架构设计")]),a._v(" "),s("h3",{attrs:{id:"_1-架构的设计原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-架构的设计原理"}},[a._v("#")]),a._v(" 1. 架构的设计原理")]),a._v(" "),s("p",[a._v("HDFS 采用 master/slave 架构。一个 HDFS 集群是由一个 Namenode 和一定数目的 Datanodes 组成。Namenode 是一个中心服务器，负责管理文件系统的名字空间 (namespace) 以及客户端对文件的访问。集群中的 Datanode 一般是一个节点一个，负责管理它所在节点上的存储。HDFS暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组 Datanode 上。 Namenode 执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体 Datanode 节点的映射。Datanode 负责处理文件系统客户端的读写请求。在 Namenode 的统一调度下进行数据块的创建、删除和复制。")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.willlu.cn/image/bigdata/hdfsarchitecture.png",alt:"HDFS_Architecture"}})]),a._v(" "),s("h3",{attrs:{id:"_2-架构的稳定性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-架构的稳定性"}},[a._v("#")]),a._v(" 2. 架构的稳定性")]),a._v(" "),s("h4",{attrs:{id:"_1-心跳机制和重新复制"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-心跳机制和重新复制"}},[a._v("#")]),a._v(" 1. 心跳机制和重新复制")]),a._v(" "),s("p",[a._v("每个 DataNode 定期向 NameNode 发送心跳消息，如果超过指定时间没有收到心跳消息，则将 DataNode 标记为死亡。NameNode 不会将任何新的 IO 请求转发给标记为死亡的 DataNode，也不会再使用这些 DataNode 上的数据。 由于数据不再可用，可能会导致某些块的复制因子小于其指定值，NameNode 会跟踪这些块，并在必要的时候进行重新复制。")]),a._v(" "),s("h4",{attrs:{id:"_2-数据的完整性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-数据的完整性"}},[a._v("#")]),a._v(" 2. 数据的完整性")]),a._v(" "),s("p",[a._v("由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性，具体操作如下：")]),a._v(" "),s("p",[a._v("当客户端创建 HDFS 文件时，它会计算文件的每个块的 "),s("code",[a._v("校验和")]),a._v("，并将 "),s("code",[a._v("校验和")]),a._v(" 存储在同一 HDFS 命名空间下的单独的隐藏文件中。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存储在关联校验和文件中的 "),s("code",[a._v("校验和")]),a._v(" 匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其他 DataNode 获取该块的其他可用副本。")]),a._v(" "),s("h4",{attrs:{id:"_3-元数据的磁盘故障"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-元数据的磁盘故障"}},[a._v("#")]),a._v(" 3.元数据的磁盘故障")]),a._v(" "),s("p",[s("code",[a._v("FsImage")]),a._v(" 和 "),s("code",[a._v("EditLog")]),a._v(" 是 HDFS 的核心数据，这些数据的意外丢失可能会导致整个 HDFS 服务不可用。为了避免这个问题，可以配置 NameNode 使其支持 "),s("code",[a._v("FsImage")]),a._v(" 和 "),s("code",[a._v("EditLog")]),a._v(" 多副本同步，这样 "),s("code",[a._v("FsImage")]),a._v(" 或 "),s("code",[a._v("EditLog")]),a._v(" 的任何改变都会引起每个副本 "),s("code",[a._v("FsImage")]),a._v(" 和 "),s("code",[a._v("EditLog")]),a._v(" 的同步更新。")]),a._v(" "),s("h4",{attrs:{id:"_4-支持快照"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-支持快照"}},[a._v("#")]),a._v(" 4.支持快照")]),a._v(" "),s("p",[a._v("快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。")]),a._v(" "),s("h2",{attrs:{id:"hdfs-的组件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-的组件"}},[a._v("#")]),a._v(" HDFS 的组件")]),a._v(" "),s("p",[a._v("HDFS 包含 NameNode、DataNode、SecondaryNameNode 三个组件。")]),a._v(" "),s("h3",{attrs:{id:"_1-namenode（名称节点）"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-namenode（名称节点）"}},[a._v("#")]),a._v(" 1. NameNode（名称节点）")]),a._v(" "),s("p",[a._v("用来管理文件系统的命名空间，负责记录文件是如何分割成数据块，以及这些数据块分别被存储到哪些数据节点上。")]),a._v(" "),s("ol",[s("li",[a._v("维护 HDFS 文件系统，是 HDFS 的主节点。")]),a._v(" "),s("li",[a._v("接受客户端（命令行、Java程序）的请求: 创建目录、上传数据、下载数据、删除数据等。")]),a._v(" "),s("li",[a._v("管理和维护HDFS的日志和元信息。\n"),s("ul",[s("li",[s("p",[a._v("第一次启动 NameNode 格式化后，创建 edits 和 fsimage 文件。如果不是第一次启动，直接加载 edits 日志和 fsimage 文件到内存。")])]),a._v(" "),s("li",[s("p",[s("strong",[a._v("日志文件（edits文件）")]),a._v("：记录的是客户端的所有操作，存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到edits文件中，同时体现了HDFS的最新的状态。")]),a._v(" "),s("p",[a._v("（*）而日志 edits文件 保存在我们配置的数据块目录中：由 hadoop.tmp.dir 参数指定。路径：$hadoop.tmp.dir/dfs/name/current")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.willlu.cn/image/bigdata/edit-20200505-102155@2x.png",alt:"edit-20200505"}})]),a._v(" "),s("p",[a._v("（*）使用 hdfs oev -i 命令查看 edit日志输出为 XML 文件：")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 举个栗子")]),a._v("\nhdfs dfs -mkdir /edit_log\nhdfs oev -i edits_inprogress_0000000000000000070 -o /tmp/log.xml\n")])])]),s("p",[s("img",{attrs:{src:"https://cdn.willlu.cn/image/bigdata/edit_log_20200505-102831@2x.png",alt:"edit_log_20200505"}})])]),a._v(" "),s("li",[s("p",[s("strong",[a._v("元信息文件（fsimage文件）")]),a._v("：记录的是数据块的位置信息、数据块的冗余信息。")]),a._v(" "),s("p",[a._v("（*）保存目录: $hadoop.tmp.dir/dfs/name/current")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.willlu.cn/image/bigdata/fsimges-20200505-104030@2x.png",alt:"fsimges-20200505"}})]),a._v(" "),s("p",[a._v("（*）使用 hdfs oiv -i 命令将 fsimges 日志输出为 XML")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 举个栗子")]),a._v("\nhdfs oiv -i fsimage_0000000000000000069 -o ~/tmp/fsimage.xml -p XML\n")])])]),s("p",[s("img",{attrs:{src:"https://cdn.willlu.cn/image/bigdata/blog-size-20200505-105144@2x.png",alt:"blog-size-20200505"}})])]),a._v(" "),s("li",[s("p",[a._v("每次 NameNod 启动的时候都会将 fsimage 文件读入内存，加载 edits 里面的所有操作，保证内存中的元数据信息是最新的、同步的，可以看成 NameNode 启动的时候就将 fsimage 和 edits 文件进行了合并。")])])])])]),a._v(" "),s("h3",{attrs:{id:"_2-datanode（数据节点）"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-datanode（数据节点）"}},[a._v("#")]),a._v(" 2. DataNode（数据节点）")]),a._v(" "),s("p",[a._v("文件系统的数据节点，根据需要存储和检索数据块，并定期向 NameNode 发送他们所存储的块列表。")]),a._v(" "),s("ol",[s("li",[s("p",[s("strong",[a._v("以数据块为单位，保存数据。")])]),a._v(" "),s("ol",[s("li",[a._v("Hadoop 1.x 的数据块大小: 64M。")]),a._v(" "),s("li",[a._v("Hadoop 2.x 的数据块大小:128M。")]),a._v(" "),s("li",[a._v("Hadoop 3.x 的数据块大小:128M。")])])]),a._v(" "),s("li",[s("p",[s("strong",[a._v("数据保存的目录:由 hadoop.tmp.dir 参数指定。如：")])]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("/usr/software/hadoop-2.10.0/tmp/dfs/data/current/BP-1940172841-192.168.3.11-1588315718387/current/finalized/subdir0/subdir0\n")])])]),s("p",[a._v("已文件的文件的形式进行保存（blk_***）")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.willlu.cn/image/bigdata/datanode-blok-20200505-110533@2x.png",alt:"datanode-blok-20200505"}})])]),a._v(" "),s("li",[s("p",[s("strong",[a._v("在全分布模式下，至少两个 DataNode 节点。")])])])]),a._v(" "),s("h3",{attrs:{id:"_3-secondarynamenode（第二名称节点）"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-secondarynamenode（第二名称节点）"}},[a._v("#")]),a._v(" 3. SecondaryNameNode（第二名称节点）")]),a._v(" "),s("p",[a._v("与 NameNode 进行通讯，定期保存 HDFS 元数据的快照，用以备份和恢复数据等操作，其中一个主要作用是进行日志的合并。")]),a._v(" "),s("ol",[s("li",[a._v("SecondaryNameNode 询问 NameNode 是否需要 checkpoint。直接带回 NameNode 是否检查结果。")]),a._v(" "),s("li",[a._v("SecondaryNameNode 请求执行 checkpoint。")]),a._v(" "),s("li",[a._v("NameNode 滚动正在写的 edits 日志。")]),a._v(" "),s("li",[a._v("将滚动前的编辑日志和镜像文件拷贝到 SecondaryNameNode。")]),a._v(" "),s("li",[a._v("SecondaryNameNode 加载编辑日志和镜像文件到内存，并合并。")]),a._v(" "),s("li",[a._v("生成新的镜像文件 fsimage.chkpoint。")]),a._v(" "),s("li",[a._v("拷贝 fsimage.chkpoint 到 NameNode。")]),a._v(" "),s("li",[a._v("NameNode 将 fsimage.chkpoint 重新命名成 fsimage。")])]),a._v(" "),s("h3",{attrs:{id:"_4-checkpoint-时间检查点设置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-checkpoint-时间检查点设置"}},[a._v("#")]),a._v(" 4. Checkpoint 时间检查点设置")]),a._v(" "),s("ol",[s("li",[a._v("通常情况下，SecondaryNameNode每隔一小时执行一次。对应的配置文件：hdfs-default.xml")])]),a._v(" "),s("div",{staticClass:"language-xml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-xml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("dfs.namenode.checkpoint.period"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("3600"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n")])])]),s("ol",{attrs:{start:"2"}},[s("li",[a._v("一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。")])]),a._v(" "),s("div",{staticClass:"language-xml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-xml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("dfs.namenode.checkpoint.txns"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("1000000"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("description")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("操作动作次数"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("description")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("dfs.namenode.checkpoint.check.period"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("60"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("description")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" 1分钟检查一次操作次数"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("description")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n")])])]),s("h3",{attrs:{id:"_5-总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-总结"}},[a._v("#")]),a._v(" 5. 总结")]),a._v(" "),s("p",[a._v("在 NameNode节点上，fsimage 保存了元数据镜像文件，而 edits中完整记录了元数据的操作日志（针对文件系统做得修改操作记录）。NameNode 内存中存储的元数据可以用“fsimage+edits”来表达。而 SecondaryNameNode 负责定时（默认1小时 或 数据达到配置量时）从 NameNode 上获取 fsimage 和 edits进行合并，然后在发送给 NameNode，减少 NameNode 的工作量。")])])}),[],!1,null,null,null);t.default=n.exports}}]);